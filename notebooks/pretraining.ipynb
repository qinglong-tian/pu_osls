{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d7777e",
   "metadata": {},
   "source": [
    "# PU/OSLS TabPFN Pretraining with Curriculum (TabICL Prior)\n",
    "\n",
    "Curriculum schedule used here is controlled by config variables:\n",
    "- `update_every_steps` (how often hyperparameters are updated)\n",
    "- `max_updates` (number of update stages before becoming stable)\n",
    "- `min_features` stays fixed while `max_features` expands over stages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1241381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for candidate in [start.resolve(), *start.resolve().parents]:\n",
    "        if (candidate / \"src\" / \"pu_osls_tabpfn\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\n",
    "        \"Could not find project root containing src/pu_osls_tabpfn. \"\n",
    "        \"Open this notebook from the repository root or install with `pip install -e .`.\"\n",
    "    )\n",
    "\n",
    "ROOT = _find_repo_root(Path.cwd())\n",
    "sys.path.insert(0, str(ROOT / \"src\"))\n",
    "\n",
    "from pu_osls_tabpfn.eval_pu_osls import EvalConfig, evaluate_pu_osls, print_results\n",
    "from pu_osls_tabpfn.model import CustomNanoTabPFNModel\n",
    "from pu_osls_tabpfn.prior_data import PriorGeneratorConfig, TabICLPriorConfig, TestLabelShiftConfig, generate_batch\n",
    "import pu_osls_tabpfn.train as train_module\n",
    "train_module = importlib.reload(train_module)\n",
    "CurriculumConfig = train_module.CurriculumConfig\n",
    "get_device = train_module.get_device\n",
    "train = train_module.train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac9252",
   "metadata": {},
   "source": [
    "## 1) Final target configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bed54a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "CurriculumConfig(enabled=True, update_every_steps=500, max_updates=20, start_max_classes=2, start_max_features=3, start_min_rows=120, start_max_rows=300, start_remove_poisson_lambda=0.3, tabicl_sampled_hp_start={'num_layers': {'max_mean': 2.0}, 'hidden_dim': {'max_mean': 24.0, 'min_mean': 4.0}, 'num_causes': {'max_mean': 4.0}})\n",
      "Curriculum updates every 500 steps\n",
      "Curriculum stabilizes after 10000 steps\n"
     ]
    }
   ],
   "source": [
    "cfg = PriorGeneratorConfig(\n",
    "    max_classes=10,\n",
    "    min_features=3,\n",
    "    max_features=8,\n",
    "    min_rows=500,\n",
    "    max_rows=1000,\n",
    "    min_train_fraction=0.4,\n",
    "    max_train_fraction=0.8,\n",
    "    remove_poisson_lambda=1.0,\n",
    "    seed=0,\n",
    "    prior_backend=\"tabicl\",\n",
    "    tabicl=TabICLPriorConfig(\n",
    "        prior_type=\"mlp_scm\",\n",
    "        n_jobs=1,\n",
    "        batch_size_per_gp=4,\n",
    "        batch_size_per_subgp=2,\n",
    "    ),\n",
    "    test_label_shift=TestLabelShiftConfig(enabled=False, strategy=\"none\", strength=0.0),\n",
    ")\n",
    "update_every_steps = 500\n",
    "max_updates = 20\n",
    "curriculum_cfg = CurriculumConfig(\n",
    "    enabled=True,\n",
    "    update_every_steps=update_every_steps,\n",
    "    max_updates=max_updates,\n",
    "    start_max_classes=2,\n",
    "    start_max_features=cfg.min_features,\n",
    "    start_min_rows=120,\n",
    "    start_max_rows=300,\n",
    "    start_remove_poisson_lambda=0.3,\n",
    "    tabicl_sampled_hp_start={\n",
    "        \"num_layers\": {\"max_mean\": 2.0},\n",
    "        \"hidden_dim\": {\"max_mean\": 24.0, \"min_mean\": 4.0},\n",
    "        \"num_causes\": {\"max_mean\": 4.0},\n",
    "    },\n",
    ")\n",
    "device = get_device()\n",
    "unseen_label = cfg.max_classes\n",
    "num_outputs = cfg.max_classes + 1\n",
    "print(f\"Device: {device}\")\n",
    "print(curriculum_cfg)\n",
    "print(f\"Curriculum updates every {curriculum_cfg.update_every_steps} steps\")\n",
    "print(f\"Curriculum stabilizes after {curriculum_cfg.update_every_steps * curriculum_cfg.max_updates} steps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fdf321",
   "metadata": {},
   "source": [
    "## 2) Quick batch sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f91640f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (4, 647, 8)\n",
      "y shape: (4, 647)\n",
      "split indices: (347, 347, 347, 245)\n",
      "num_classes: (2, 2, 8, 8)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'num_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33msplit indices:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(batch[\u001b[33m\"\u001b[39m\u001b[33mtrain_test_split_index\u001b[39m\u001b[33m\"\u001b[39m].tolist()))\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnum_classes:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(batch[\u001b[33m\"\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m\"\u001b[39m].tolist()))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnum_features:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_features\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.tolist()))\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mremoved_class_count:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(batch[\u001b[33m\"\u001b[39m\u001b[33mremoved_class_count\u001b[39m\u001b[33m\"\u001b[39m].tolist()))\n",
      "\u001b[31mKeyError\u001b[39m: 'num_features'"
     ]
    }
   ],
   "source": [
    "batch = generate_batch(cfg, batch_size=4, device=device, rng=np.random.default_rng(cfg.seed))\n",
    "print(\"x shape:\", tuple(batch[\"x\"].shape))\n",
    "print(\"y shape:\", tuple(batch[\"y\"].shape))\n",
    "print(\"split indices:\", tuple(batch[\"train_test_split_index\"].tolist()))\n",
    "print(\"num_classes:\", tuple(batch[\"num_classes\"].tolist()))\n",
    "print(\"num_features:\", tuple(batch[\"num_features\"].tolist()))\n",
    "print(\"removed_class_count:\", tuple(batch[\"removed_class_count\"].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc39ec8",
   "metadata": {},
   "source": [
    "## 3) Train with curriculum\n",
    "\n",
    "Choose `num_steps` for your run; the schedule above determines when updates happen and when curriculum stabilizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cacab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomNanoTabPFNModel(\n",
    "    embedding_size=32,\n",
    "    num_attention_heads=4,\n",
    "    mlp_hidden_size=64,\n",
    "    num_layers=2,\n",
    "    num_outputs=num_outputs,\n",
    "    unseen_label=unseen_label,\n",
    ")\n",
    "eval_cfg = EvalConfig(n_tasks=100, batch_size=8, seed=999, outlier_score=\"msp\")\n",
    "model, losses = train(\n",
    "    model,\n",
    "    cfg,\n",
    "    batch_size=8,\n",
    "    lr=5e-4,\n",
    "    device=device,\n",
    "    num_steps=1200,\n",
    "    unseen_label=unseen_label,\n",
    "    eval_cfg=eval_cfg,\n",
    "    eval_interval=0,\n",
    "    curriculum_cfg=curriculum_cfg,\n",
    ")\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7d835",
   "metadata": {},
   "source": [
    "## 4) Final evaluation + checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_pu_osls(\n",
    "    model,\n",
    "    cfg_prior=cfg,\n",
    "    unseen_label=unseen_label,\n",
    "    device=device,\n",
    "    eval_cfg=eval_cfg,\n",
    ")\n",
    "print_results(results)\n",
    "\n",
    "artifacts_dir = ROOT / \"artifacts\"\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "checkpoint_path = artifacts_dir / \"pretrained_pu_osls_tabpfn.pt\"\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"cfg\": cfg,\n",
    "        \"curriculum_cfg\": curriculum_cfg,\n",
    "        \"eval_cfg\": eval_cfg,\n",
    "        \"unseen_label\": unseen_label,\n",
    "    },\n",
    "    checkpoint_path,\n",
    ")\n",
    "print(f\"Saved checkpoint to: {checkpoint_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
