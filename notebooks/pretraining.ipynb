{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d7777e",
   "metadata": {},
   "source": [
    "# PU/OSLS TabPFN Pretraining with Curriculum (TabICL Prior)\n",
    "\n",
    "Curriculum schedule used here is controlled by config variables:\n",
    "- `update_every_steps` (how often hyperparameters are updated)\n",
    "- `max_updates` (number of update stages before becoming stable)\n",
    "- `min_features` stays fixed while `max_features` expands over stages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for candidate in [start.resolve(), *start.resolve().parents]:\n",
    "        if (candidate / \"src\" / \"pu_osls_tabpfn\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\n",
    "        \"Could not find project root containing src/pu_osls_tabpfn. \"\n",
    "        \"Open this notebook from the repository root or install with `pip install -e .`.\"\n",
    "    )\n",
    "\n",
    "ROOT = _find_repo_root(Path.cwd())\n",
    "sys.path.insert(0, str(ROOT / \"src\"))\n",
    "\n",
    "from pu_osls_tabpfn.eval_pu_osls import EvalConfig, evaluate_pu_osls, print_results\n",
    "from pu_osls_tabpfn.model import CustomNanoTabPFNModel\n",
    "from pu_osls_tabpfn.prior_data import PriorGeneratorConfig, TabICLPriorConfig, TestLabelShiftConfig, generate_batch\n",
    "import pu_osls_tabpfn.train as train_module\n",
    "train_module = importlib.reload(train_module)\n",
    "CurriculumConfig = train_module.CurriculumConfig\n",
    "get_device = train_module.get_device\n",
    "train = train_module.train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac9252",
   "metadata": {},
   "source": [
    "## 1) Final target configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed54a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = PriorGeneratorConfig(\n",
    "    max_classes=5,\n",
    "    min_features=4,\n",
    "    max_features=10,\n",
    "    min_rows=800,\n",
    "    max_rows=1000,\n",
    "    min_train_fraction=0.5,\n",
    "    max_train_fraction=0.6,\n",
    "    remove_poisson_lambda=1.2,\n",
    "    min_train_rows_after_removal=30,\n",
    "    seed=99,\n",
    "    prior_backend=\"tabicl\",\n",
    "    tabicl=TabICLPriorConfig(\n",
    "        prior_type=\"mlp_scm\",\n",
    "        n_jobs=1,\n",
    "        batch_size_per_gp=4,\n",
    "        batch_size_per_subgp=2,\n",
    "    ),\n",
    "    test_label_shift=TestLabelShiftConfig(enabled=False, strategy=\"none\", strength=0.0),\n",
    ")\n",
    "update_every_steps = 100\n",
    "max_updates = 20\n",
    "curriculum_cfg = CurriculumConfig(\n",
    "    enabled=True,\n",
    "    update_every_steps=update_every_steps,\n",
    "    max_updates=max_updates,\n",
    "    start_max_classes=3,\n",
    "    start_max_features=cfg.min_features,\n",
    "    start_min_rows=700,\n",
    "    start_max_rows=800,\n",
    "    start_remove_poisson_lambda=0.3,\n",
    "    tabicl_sampled_hp_start={\n",
    "        \"num_layers\": {\"max_mean\": 2.0},\n",
    "        \"hidden_dim\": {\"max_mean\": 24.0, \"min_mean\": 4.0},\n",
    "        \"num_causes\": {\"max_mean\": 4.0},\n",
    "    },\n",
    ")\n",
    "device = get_device()\n",
    "unseen_label = cfg.max_classes\n",
    "num_outputs = cfg.max_classes + 1\n",
    "print(f\"Device: {device}\")\n",
    "print(curriculum_cfg)\n",
    "print(f\"Curriculum updates every {curriculum_cfg.update_every_steps} steps\")\n",
    "print(f\"Curriculum stabilizes after {curriculum_cfg.update_every_steps * curriculum_cfg.max_updates} steps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fdf321",
   "metadata": {},
   "source": [
    "## 2) Quick batch sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91640f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = generate_batch(cfg, batch_size=4, device=device, rng=np.random.default_rng(cfg.seed))\n",
    "print(\"x shape:\", tuple(batch[\"x\"].shape))\n",
    "print(\"y shape:\", tuple(batch[\"y\"].shape))\n",
    "print(\"split indices:\", tuple(batch[\"train_test_split_index\"].tolist()))\n",
    "print(\"num_classes:\", tuple(batch[\"num_classes\"].tolist()))\n",
    "print(\"num_features:\", tuple(batch[\"num_features\"].tolist()))\n",
    "print(\"removed_class_count:\", tuple(batch[\"removed_class_count\"].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc39ec8",
   "metadata": {},
   "source": [
    "## 3) Train with curriculum\n",
    "\n",
    "Choose `num_steps` for your run; the schedule above determines when updates happen and when curriculum stabilizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a) GPU memory profiling for a given config\n",
    "\n",
    "Run this before full training to estimate peak CUDA memory for a chosen curriculum step and batch size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_gpu_step(model, cfg, curriculum_cfg, step, batch_size, unseen_label, device):\n",
    "    assert device.type == \"cuda\", \"GPU profiling requires CUDA.\"\n",
    "\n",
    "    from pu_osls_tabpfn.prior_data import generate_batch\n",
    "    from pu_osls_tabpfn.train import _build_step_cfg\n",
    "\n",
    "    model = model.to(device).train()\n",
    "    step_cfg = _build_step_cfg(cfg, step=step, curriculum_cfg=curriculum_cfg)\n",
    "    batch = generate_batch(\n",
    "        step_cfg,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        rng=np.random.default_rng(cfg.seed + step),\n",
    "    )\n",
    "\n",
    "    x = batch[\"x\"]\n",
    "    y_full = batch[\"y\"]\n",
    "    split = batch[\"train_test_split_index\"]\n",
    "\n",
    "    max_split = int(split.max().item())\n",
    "    y_train_padded = torch.full(\n",
    "        (x.shape[0], max_split),\n",
    "        fill_value=unseen_label,\n",
    "        device=x.device,\n",
    "        dtype=y_full.dtype,\n",
    "    )\n",
    "    for b in range(x.shape[0]):\n",
    "        split_b = int(split[b].item())\n",
    "        y_train_padded[b, :split_b] = y_full[b, :split_b]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    try:\n",
    "        logits = model((x, y_train_padded), split)\n",
    "        loss = logits.float().mean()\n",
    "        loss.backward()\n",
    "\n",
    "        peak_alloc = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        peak_reserved = torch.cuda.max_memory_reserved() / 1024**3\n",
    "        free, total = torch.cuda.mem_get_info()\n",
    "        print(f\"step={step}, batch_size={batch_size}\")\n",
    "        print(f\"curriculum rows={step_cfg.min_rows}-{step_cfg.max_rows}, features={step_cfg.min_features}-{step_cfg.max_features}\")\n",
    "        print(f\"peak allocated: {peak_alloc:.2f} GiB\")\n",
    "        print(f\"peak reserved : {peak_reserved:.2f} GiB\")\n",
    "        print(f\"free/total    : {free/1024**3:.2f}/{total/1024**3:.2f} GiB\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"OOM/runtime error:\", str(e).split(\"\\n\")[0])\n",
    "\n",
    "\n",
    "# Example probes:\n",
    "# profile_gpu_step(model, cfg, curriculum_cfg, step=0, batch_size=64, unseen_label=unseen_label, device=device)\n",
    "# profile_gpu_step(model, cfg, curriculum_cfg, step=2000, batch_size=16, unseen_label=unseen_label, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cacab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomNanoTabPFNModel(\n",
    "    embedding_size=32,\n",
    "    num_attention_heads=4,\n",
    "    mlp_hidden_size=64,\n",
    "    num_layers=3,\n",
    "    num_outputs=num_outputs,\n",
    "    unseen_label=unseen_label,\n",
    ")\n",
    "\n",
    "# Optional re-check before long training:\n",
    "# profile_gpu_step(model, cfg, curriculum_cfg, step=20000, batch_size=64, unseen_label=unseen_label, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41760c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cfg = EvalConfig(n_tasks=100, batch_size=8, seed=999, outlier_score=\"msp\")\n",
    "model, losses = train(\n",
    "    model,\n",
    "    cfg,\n",
    "    batch_size=64,\n",
    "    lr=2e-4,\n",
    "    device=device,\n",
    "    num_steps=30000,\n",
    "    unseen_label=unseen_label,\n",
    "    eval_cfg=eval_cfg,\n",
    "    eval_interval=0,\n",
    "    curriculum_cfg=curriculum_cfg,\n",
    ")\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7d835",
   "metadata": {},
   "source": [
    "## 4) Final evaluation + checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_pu_osls(\n",
    "    model,\n",
    "    cfg_prior=cfg,\n",
    "    unseen_label=unseen_label,\n",
    "    device=device,\n",
    "    eval_cfg=eval_cfg,\n",
    ")\n",
    "print_results(results)\n",
    "\n",
    "artifacts_dir = ROOT / \"artifacts\"\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "checkpoint_path = artifacts_dir / \"pretrained_pu_osls_tabpfn.pt\"\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"cfg\": cfg,\n",
    "        \"curriculum_cfg\": curriculum_cfg,\n",
    "        \"eval_cfg\": eval_cfg,\n",
    "        \"unseen_label\": unseen_label,\n",
    "    },\n",
    "    checkpoint_path,\n",
    ")\n",
    "print(f\"Saved checkpoint to: {checkpoint_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
